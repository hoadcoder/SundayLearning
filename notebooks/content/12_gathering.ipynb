{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Gathering\n",
    "Gathering é o primeiro passo da etapa de Data Wrangling.\n",
    "\n",
    "**Best Practice:** Download de arquivos programaticamente.\n",
    "\n",
    "**Motivo:**\n",
    "\n",
    "* Scalability: Essa automação poupa tempo e previne erros.\n",
    "* Reproducibility: Qualquer um pode reproduzir seu trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicar o que é o ciclo **REQUEST - RESPONSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_dir = \"world_data\"\n",
    "\n",
    "if not os.path.exists(main_data_dir):\n",
    "    os.makedirs(main_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the zipped file\n",
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/kaggle-data-sets/1844/3192/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1588731384&Signature=OvJwgiXmSCy6znB2fQ96%2BUDvqHNzIEJb52DJilVXEdZvh2RLarUgzBEO2KcCDcnZwUXqSWTzqgEfsIE7%2F7WR2PHoBKuFDLBlrgK%2FQwIfE6M%2Fj8BdVhe%2FnsnCQaKSVF14cQB7tFcg6F8CcHYkVEKdokotXwHVViVwn4%2Br3owzoXfsMCaOum9CVXJd429hiUgUB5vXO4HCDtpVMflFGAnsc8JDK5jnmyfGw8TNGb2qLZaJZ8S7%2BiriLX6acCwiMvGz3L2%2BhRVzZvUddKm57C8OLXMsFrTvkicZXbIA9WHfMuxBKb1g4OLV0WNBKO27A43%2B0KQ2wzmApSvAbk4rcGMe4A%3D%3D&response-content-disposition=attachment%3B+filename%3Darmenian-online-job-postings.zip\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(os.path.join(main_data_dir, \"armenian-online-job-postings.zip\"), mode=\"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unizzipng the zipped file\n",
    "import zipfile\n",
    "\n",
    "# Create directory if it yet doesn't exist\n",
    "extract_dir = os.path.join(main_data_dir, \"armenian_data\")\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(main_data_dir, \"armenian-online-job-postings.zip\"), \"r\") as meu_zip:\n",
    "    meu_zip.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = pd.read_csv(os.path.join(extract_dir, \"online-job-postings.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Assessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 5 rows\n",
    "df_job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last 5 rows.\n",
    "df_job.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataframe info\n",
    "df_job.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summarize a list with quantity of each category.\n",
    "df_job[\"StartDate\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "*dataframe1*\n",
    "\n",
    "* Start Data possui vários valores que representam a mesma coisa: ASAP\n",
    "* Nomes das colunas não estão no padrão\n",
    "* Colunas `ApplicationC` e `AboutC` não são descritivas o suficiente\n",
    "\n",
    "*dataframe2*\n",
    "\n",
    "#### Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning \n",
    "\n",
    "Improving the **quality** of a dataset or cleaning the dataset do not means: Changing the data (because it could be **data fraud**).\n",
    "\n",
    "The meaning of Cleaning is correcting the data or removing the data.\n",
    "\n",
    "* Innacurate, wrong or irrelevant data.\n",
    "* Replacing or filling (NULL or NA values) data.\n",
    "* Combining/Merging datasets.\n",
    "\n",
    "Improving the **tidiness** is transform the dataset to follow:\n",
    "\n",
    "* each observation = row\n",
    "* each variable = column\n",
    "\n",
    "There are two ways to cleaning the data: manually and programmatic.\n",
    "\n",
    "#### Manually\n",
    "\n",
    "To be avoided.\n",
    "\n",
    "#### Programmatic\n",
    "\n",
    "There are three steps:\n",
    "\n",
    "1. Define\n",
    "2. Code\n",
    "3. Test\n",
    "\n",
    ">**Defining** means defining a data cleaning plan in writing, where we turn our assessments into defined cleaning tasks. This plan will also serve as an instruction list so others (or us in the future) can look at our work and reproduce it.\n",
    "\n",
    ">**Coding** means translating these definitions to code and executing that code.\n",
    "\n",
    ">**Testing** means testing our dataset, often using code, to make sure our cleaning operations worked.\n",
    "\n",
    "Text from the class notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of original\n",
    "df_clean = df_job.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Fixing the columns header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns = [col.lower() for col in df_clean.columns]\n",
    "\n",
    "df_clean = df_clean.rename(columns={\"applicationp\": \"application_procedure\",\n",
    "                                    \"aboutc\": \"about_company\",\n",
    "                                    \"requiredqual\": \"required_qualifications\",\n",
    "                                    \"job_requirment\": \"job_requirements\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Set single name for ASAP start_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asap_list = []\n",
    "\n",
    "for start_date in df_clean.startdate.dropna().unique():\n",
    "    \n",
    "    lower_str = start_date.lower()\n",
    "    \n",
    "    if \"immediat\" in lower_str or \"asap\" in lower_str or \"as soon as possible\" in lower_str  or \\\n",
    "    \"earliest\" in lower_str or \"upon\" in lower_str:\n",
    "        asap_list.append(start_date)\n",
    "\n",
    "asap_list.pop(asap_list.index('Upon availability'))\n",
    "asap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_asap(row):\n",
    "    start_date = row[\"startdate\"]\n",
    "    \n",
    "    if pd.isna(start_date):\n",
    "        return np.nan\n",
    "    \n",
    "    if start_date in asap_list:\n",
    "        return \"ASAP\"\n",
    "    else:\n",
    "        return start_date\n",
    "\n",
    "    \n",
    "df_clean[\"startdate\"] = df_clean.apply(replace_asap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"startdate\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"clean-online-job-postings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
