{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataframe e o chamando de raw\n",
    "df_raw = pd.read_csv(\"world_data/country_gen_info.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se o dataframe foi carregado corretamente e entender a estrutura\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os valores nulos e os tipos das colunas\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma cópia do dataframe cru para fazer manipulações sem alterar o original\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poderia trocar o tipo da coluna murderers para inteiro.\n",
    "# Mas, como os dados dessa coluna foram inferências estatísticas, acredito que é ok ter deixá-los decimais\n",
    "\n",
    "# df[\"muderers\"] = df[\"muderers\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lembrar dos padrões de nome de coluna \n",
    "# -> Tudo em minúsculo\n",
    "# -> Sem caracteres especiais\n",
    "# -> Underscores (_) no lugar de espaços\n",
    "\n",
    "df.columns = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as dimensões do dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando estatísticas das colunas numéricas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando um ou mais vetores (vetor/matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notação colchetes\n",
    "df[\"pib\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notação .\n",
    "df.pib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando dois vetores (uma matris) de uma única vez\n",
    "df[[\"pib\", \"life_expect\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona valores específicos\n",
    "# Getting ou Setting uma célula específica\n",
    "# O campo antes da vírgula se refere ao índice da linha. Após a vírgula vem a coluna\n",
    "df.loc[1, \"pib\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possível, também, passar uma lista de indices e/ou de colunas\n",
    "df.loc[[1, 4, 9], [\"pib\", \"murderers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ou intervalos de índices e/ou colunas\n",
    "df.loc[1:10, \"pib\":\"murderers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtros notação colchetes\n",
    "# & deve ser usado no lugar do and\n",
    "# | deve ser usado no lugar do or\n",
    "# ~ deve ser usado no lugar de not\n",
    "# & e | vêm entre comparações, exemplo: (df[\"country\"] == 'Afghanistan') & (df[\"year\"] > 1900)\n",
    "# ~ vem antes de uma comparação - a fim de mudar o resultado da comparaçõ, exemplo: ~(df[\"country\"] == 'Afghanistan')\n",
    "\n",
    "country = \"Afghanistan\"\n",
    "year = 1900\n",
    "\n",
    "df[(df[\"country\"] == country) & (df[\"year\"] > year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesmo filtro que o realizado acima, entretanto, com a notação .query\n",
    "country = \"Afghanistan\"\n",
    "year = 1900\n",
    "\n",
    "df.query(\"country == '{}' & year > {}\".format(country, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método UNIQUE\n",
    "# Retorna os valores únicos de um vetor\n",
    "# No caso abaixo, os valores únicos da coluna/vetor year\n",
    "df.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método NUNIQUE\n",
    "# Retorna a quantidade de valores únicos de um vetor\n",
    "# No caso abaixo, a quantidade de valores únicos da coluna/vetor year\n",
    "df[\"year\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método VALUE_COUNTS\n",
    "# Retorna a quantidade de cada um dos diferentes de um vetor\n",
    "# No caso abaixo, a quantidade de cada ano na coluna year\n",
    "df[\"year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quaisquer outras funções numpy podem ser usadas nos vetores \n",
    "# Exeplos:\n",
    "# .max()\n",
    "# .min()\n",
    "# .mean()\n",
    "# .median()\n",
    "# .std()\n",
    "\n",
    "df[\"year\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Como uma coluna é um vetor numpy, podemos fazer operações entre vetores\n",
    "# Chamamos essas operações de 'vectorized operations'\n",
    "# São mais rápidas que operações que usam loops que iteram linha a linha, visto que\n",
    "# operações vetorizados são executadas de uma única vez.\n",
    "\n",
    "# No exemplo abaixo, dividimos a coluna (vetor) murderers pela coluna (vetor) population\n",
    "df[\"murderers\"] / df[\"population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambas as colunas murderers e population vieram do mesmo dataframe\n",
    "# Isso significa que elas certamente possuem a mesma quantidade de elementos\n",
    "# Também significa que o vetor resultante terá a mesma quantidade de elementos dos vetores dividendo e divisor\n",
    "# Sendo assim, podemos criar uma nova coluna no nosso dataframe que é esse vetor resultante\n",
    "\n",
    "df[\"murderer_prop\"] = df[\"murderers\"] / df[\"population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verificando se a nova coluna foi de fato criada\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método SORT_VALUES\n",
    "# Ordena um dataframe pela(s) coluna(s) passadas no parâmetro 'by'\n",
    "# Retorna uma nova versão ordenada do dataframe caso o parâmetro inplace=True não seja passado.\n",
    "# Caso o inplace=True seja passado, o dataframe é de fato reordenado.\n",
    "df.sort_values(by=\"murderers\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duas formas de ordenar o dataframe por alguma(s) coluna(s)\n",
    "\n",
    "# Com inplace=False (False é o valor default para o parâmetro inplace)\n",
    "# Assim, o método retorna uma nova versão ordenada do dataframe.\n",
    "# Portanto, se queremos atualizar o dataframe, devemos dizer que a variável do dataframe deve receber\n",
    "# a nova versão ordenada do próprio dataframe.\n",
    "df = df.sort_values(by=\"murderer_prop\", ascending=False)\n",
    "\n",
    "# Uma segunda forma e, também, mais recomendada é utilizando o parâmetro inplace=True\n",
    "# Isso altera o próprio dataframe, sem retornar qualquer nova versão.\n",
    "df.sort_values(by=\"murderer_prop\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após reordenar o dataframe, é comum que os indices das linhas fiquem embaralhados.\n",
    "# Uma forma de resolver isso é utilizando o método RESET_INDEX\n",
    "# E, assim como o sort_values, podemos atualizar o dataframe com o index resetado de duas formas: \n",
    "# com inplace=False ou inplace=True:\n",
    "df = df.reset_index(drop=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É muito comum querermos agregar alguns valores.\n",
    "# Usamos a função groupby para isso, o parâmetro será a(s) coluna(s) - caso for passar várias colunas, é importante que\n",
    "# seja dentro de uma lista -  para a(s) qual(is) o dataframe será agrupado.\n",
    "\n",
    "# No caso abaixo, agrupados por 'year'\n",
    "# Após agrupar por uma coluna X, é importante aplicar uma função de agregação ou função numpy em outra coluna != X.\n",
    "# Funções de agregação são funções que, em geral, pegam vários valores e retorna apenas um\n",
    "# Por exemplo: .max(), pois ela recebe um vetor e retorna apenas o maior valor desse vetor.\n",
    "# Outras funções que não agregam podem ser usadas, como value_counts()\n",
    "\n",
    "# No caso abaixo, eu agrupei por ano a fim de verificar qual foi o maior pib em cada ano\n",
    "df.groupby(\"year\")[\"pib\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui, a ideia é mostrar a concatenação de dataframes.\n",
    "# Crio dois dataframes diferentes e a ideia é \"colar\" um embaixo do outro.\n",
    "\n",
    "# Primeiro vou criar os dataframes\n",
    "dic = {\n",
    "    \"nomes\": [\"italo\", \"bruna\", \"mauraia\"],\n",
    "    \"idades\": [23, 24, 25]\n",
    "}\n",
    "\n",
    "a_gente_df = pd.DataFrame(dic)\n",
    "\n",
    "\n",
    "dic = {\n",
    "    \"nomes\": [\"arthur\", \"joao\", \"caio\"],\n",
    "    \"idades\": [19, 20, 21]\n",
    "}\n",
    "\n",
    "eles_df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o primeiro dataframe criado\n",
    "a_gente_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o segundo dataframe criado\n",
    "eles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beleza, agora que verifiquei que foram criados corretamente, eu posso colar um dataframe abaixo do outro\n",
    "# Utilizamos para isso, o método pd.concat()\n",
    "# O dataframe resultante da concatenação é armazenado na variável todos_df\n",
    "todos_df = pd.concat([a_gente_df, eles_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando todos_df\n",
    "todos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parece que o índice está se repetindo, vamos corrigir:\n",
    "todos_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, para revisar o método FILLNA\n",
    "# Vamos setar algumas células como nulos\n",
    "# O valor que represanta NULO é o valor da biblioteca numpy mostrado abaixo:\n",
    "\n",
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionamos 2 células do dataframe para atribuir valores nulos\n",
    "todos_df.loc[0, \"idades\"] = np.nan\n",
    "todos_df.loc[4, \"nomes\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando\n",
    "todos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método FILLNA\n",
    "# Assim como vários outros métodos do pandas, o método fillna tem o mesmo esquema do parâmetro inplace\n",
    "# inplace=False, retorna uma nova versão do dataframe sem alterar o dataframe em questão\n",
    "# inplace=True, retorna o dataframe em questão\n",
    "\n",
    "# Quando chamamos o método fillna() diretamente do dataframe, a função preenche todo e qualquer valor nulo com o valor\n",
    "# passado como parâmetro. Nesse caso, a string \"VALOR_NULO\"\n",
    "todos_df.fillna(\"VALOR_NULO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso quiséssemos preencher os valores nulos de uma coluna diferente dos valores nulos de outra coluna,\n",
    "# Devemos chamar o método a partir da coluna em questão, conforme abaixo.\n",
    "\n",
    "todos_df[\"nomes\"].fillna(\"NOME_DESCONHECIDO\", inplace=True)\n",
    "todos_df[\"idades\"].fillna(\"IDADE_DESCONHECIDA\", inplace=True)\n",
    "\n",
    "# Veja que já colocamos inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando como ficou\n",
    "todos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relembrando a questão de renomear apenas colunas específicas do dataframe.\n",
    "# Passamos no parâmetro columns um dicionário cuja chave é o nome da coluna atual, e o valor para a respectiva chave\n",
    "# é o novo nome da coluna em questão.\n",
    "\n",
    "\n",
    "df.rename(columns={\"murderer_prop\": \"murderer_proportion\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método duplicated retorna um vetor booleano indicando qual índice (linha) é duplicata e qual não é\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como o vetor é muito grande, não dá para sair procurando se tem um valor True em milhares de valores.\n",
    "# Uma facilidade é utilizar o método .any() que verifica se num vetor ou lista existe pelo menos um True\n",
    "\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No caso acima, não há nenhuma duplicata pois any() retornou False.\n",
    "# Um método amigo do any() é o .all() que verifica se todos os vetores são True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método APPLY\n",
    "# Ele itera o dataframe linha por linha, passando cada linha como parâmetro para a função que está como função do método apply\n",
    "# Para ficar menos confuso, um exemplo:\n",
    "# Neste exemplo, vou querer recriar a coluna murderer_proportion de forma iterada usando o método apply.\n",
    "# Primeiro, vou dropar a coluna atual\n",
    "df.drop(\"murderer_proportion\", axis=1, inplace=True)\n",
    "\n",
    "# Agora, vou definir a função para onde o método apply jogará cada uma das linhas durante a iteração\n",
    "# Essa função recebe um único parâmetro (que será a linha passada pelo método apply) e retorna a divisão dos valores\n",
    "# murderers e population da linha em questão\n",
    "def calc_murd_prop(row):\n",
    "    return row[\"murderers\"] / row[\"population\"]\n",
    "\n",
    "# Enfim, chamamos a função .apply() que vai passar cada linha do dataframe, uma por vez, para a função calc_murd_prop\n",
    "# definida acima. Ao final, teremos um vetor do mesmo número de elemntos do nosso dataframe\n",
    "df[\"murderer_proportion\"] = df.apply(calc_murd_prop, axis=1)\n",
    "\n",
    "\n",
    "# Uma outra forma de fazer os dois passos acima é utilizando a função anônima lambda.\n",
    "# Funções anônimas são muito utilizadas no método apply visto que na maioria das vezes\n",
    "# A função a ser aplicada sobre cada linha é bastante simples e só será usada uma vez\n",
    "df[\"murderer_proportion\"] = df.apply(lambda row: row[\"murderers\"] / row[\"population\"], axis=1)\n",
    "\n",
    "\n",
    "# Note: o parâmetro axis=1 define que a iteração ocorrerá linha por linha, e não coluna por coluna\n",
    "# É importante setar esse parâmetro, uma vez que o padrão é iterar coluna por coluna, ou seja, axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se a coluna foi recriada corretamente\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
